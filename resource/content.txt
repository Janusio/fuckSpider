《Python爬虫：入门+进阶》大纲

第一章：Python 爬虫入门

1、什么是爬虫
网址构成和翻页机制
网页源码结构及网页请求过程
爬虫的应用及基本原理

2、初识Python爬虫
Python爬虫环境搭建
创建第一个爬虫：爬取百度首页
爬虫三步骤：获取数据、解析数据、保存数据

3、使用Requests爬取豆瓣短评
Requests的安装和基本用法
用Requests 爬取豆瓣短评信息
一定要知道的爬虫协议

4、使用Xpath解析豆瓣短评
解析神器Xpath的安装及介绍
Xpath的使用：浏览器复制和手写
实战：用 Xpath 解析豆瓣短评信息

5、使用pandas保存豆瓣短评数据
pandas 的基本用法介绍
pandas文件保存、数据处理
实战：使用pandas保存豆瓣短评数据

6、浏览器抓包及headers设置（案例一：爬取知乎）
爬虫的一般思路：抓取、解析、存储
浏览器抓包获取Ajax加载的数据
设置headers 突破反爬虫限制
实战：爬取知乎用户数据

7、数据入库之MongoDB（案例二：爬取拉勾）
MongoDB及RoboMongo的安装和使用
设置等待时间和修改信息头
实战：爬取拉勾职位数据
将数据存储在MongoDB中
补充实战：爬取微博移动端数据

8、Selenium爬取动态网页（案例三：爬取淘宝）
动态网页爬取神器Selenium搭建与使用
分析淘宝商品页面动态信息
实战：用Selenium 爬取淘宝网页信息


第二章：Python爬虫之Scrapy框架

1、爬虫工程化及Scrapy框架初窥
html、css、js、数据库、http协议、前后台联动
爬虫进阶的工作流程
Scrapy组件：引擎、调度器、下载中间件、项目管道等
常用的爬虫工具：各种数据库、抓包工具等

2、Scrapy安装及基本使用
Scrapy安装
Scrapy的基本方法和属性
开始第一个Scrapy项目

3、Scrapy选择器的用法
常用选择器：css、xpath、re、pyquery
css的使用方法
xpath的使用方法
re的使用方法
pyquery的使用方法

4、Scrapy的项目管道
Item Pipeline的介绍和作用
Item Pipeline的主要函数
实战举例：将数据写入文件
实战举例：在管道里过滤数据

5、Scrapy的中间件
下载中间件和蜘蛛中间件
下载中间件的三大函数
系统默认提供的中间件

6、Scrapy的Request和Response详解
Request对象基础参数和高级参数
Request对象方法
Response对象参数和方法
Response对象方法的综合利用详解


第三章：Python爬虫进阶操作

1、网络进阶之谷歌浏览器抓包分析
http请求详细分析
网络面板结构
过滤请求的关键字方法
复制、保存和清除网络信息
查看资源发起者和依赖关系

2、数据入库之去重与数据库
数据去重
数据入库MongoDB


第四章：分布式爬虫及实训项目

1、大规模并发采集——分布式爬虫的编写
分布式爬虫介绍
Scrapy分布式爬取原理
Scrapy-Redis的使用
Scrapy分布式部署详解

2、实训项目（一）——58同城二手房监控

3、实训项目（二）——去哪儿网模拟登陆

4、实训项目（三）——京东商品数据抓取